{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from os import listdir\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import torchmetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver:\n",
    "    def train(\n",
    "        self,\n",
    "        model,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        device,\n",
    "        train_loader,\n",
    "        epoch,\n",
    "        metrics,\n",
    "    ):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        start_time = time.time()\n",
    "        iteration = 0\n",
    "\n",
    "        for metric in metrics:\n",
    "            metric.to(device)\n",
    "            metric.reset()\n",
    "\n",
    "        bar = tqdm(train_loader)\n",
    "        for data in bar:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(data)\n",
    "\n",
    "            loss = criterion(output, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            for metric in metrics:\n",
    "                metric.update(output, data)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            iteration += 1\n",
    "            bar.set_postfix({\"Loss\": format(epoch_loss / iteration, \".6f\")})\n",
    "\n",
    "        metric_values = [metric.compute().item() for metric in metrics]\n",
    "\n",
    "        print(f\"\\rTrain Epoch: {epoch}, elapsed time: {time.time() - start_time:.2f}s\")\n",
    "        return epoch_loss, metric_values\n",
    "\n",
    "    def test(self, *, model, criterion, test_loader, device, metrics):\n",
    "        model.eval()\n",
    "        loss = 0\n",
    "\n",
    "        for metric in metrics:\n",
    "            metric.to(device)\n",
    "            metric.reset()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                data = data.to(device)\n",
    "                output = model(data)\n",
    "\n",
    "                loss += criterion(output, data).item()\n",
    "\n",
    "                for metric in metrics:\n",
    "                    metric.update(output, data)\n",
    "\n",
    "        metric_values = [metric.compute().item() for metric in metrics]\n",
    "\n",
    "        return loss, metric_values\n",
    "\n",
    "    def training(\n",
    "        self,\n",
    "        *,\n",
    "        model,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        scheduler,\n",
    "        device,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        epochs,\n",
    "        metrics,\n",
    "        name_file: str,\n",
    "        writing=False,\n",
    "        warmup_steps=-1,\n",
    "        warmup_scheduler=None,\n",
    "        tolerance=-1,\n",
    "        tolerance_delta=1e-4,\n",
    "    ):\n",
    "        writer = SummaryWriter(comment=f\"{name_file}\")\n",
    "\n",
    "        best_metric_value = [0.0]\n",
    "        not_improving = 0\n",
    "        last_loss = None\n",
    "\n",
    "        best_model_wts = deepcopy(model.state_dict())\n",
    "        best_optimizer = deepcopy(optimizer.state_dict())\n",
    "        metrics_1, metrics_2 = deepcopy(metrics), deepcopy(metrics)\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train_loss, train_metrics = self.train(\n",
    "                model=model,\n",
    "                device=device,\n",
    "                train_loader=train_loader,\n",
    "                criterion=criterion,\n",
    "                optimizer=optimizer,\n",
    "                epoch=epoch,\n",
    "                metrics=metrics_1,\n",
    "            )\n",
    "\n",
    "            test_loss, test_metrics = self.test(\n",
    "                model=model,\n",
    "                device=device,\n",
    "                test_loader=test_loader,\n",
    "                criterion=criterion,\n",
    "                metrics=metrics_2,\n",
    "            )\n",
    "\n",
    "            if epoch < warmup_steps:\n",
    "                warmup_scheduler.step(train_loss)\n",
    "            else:\n",
    "                scheduler.step(train_loss)\n",
    "\n",
    "            if (\n",
    "                test_metrics[0] > best_metric_value[0]\n",
    "            ):  # Assuming the first metric is the main one\n",
    "                best_metric_value = test_metrics\n",
    "                best_model_wts = deepcopy(model.state_dict())\n",
    "                best_optimizer = deepcopy(optimizer.state_dict())\n",
    "\n",
    "            if writing:\n",
    "                writer.add_scalars(\n",
    "                    \"Loss\", {\"train\": train_loss, \"test\": test_loss}, epoch\n",
    "                )\n",
    "\n",
    "                writer.add_scalars(\n",
    "                    \"Metrics\",\n",
    "                    {\"train\": train_metrics[0], \"test\": test_metrics[0]},\n",
    "                    epoch,\n",
    "                )\n",
    "\n",
    "            print(\n",
    "                f\"Train Metric: {train_metrics[0]:.10f}, Test Metric: {test_metrics[0]:.10f}\"\n",
    "            )\n",
    "            print(f\"Train Loss: {train_loss:.610}, Test Loss: {test_loss:.10f}\")\n",
    "\n",
    "            if epoch != 1:\n",
    "                if abs(train_loss - last_loss) < tolerance_delta:\n",
    "                    not_improving += 1\n",
    "                    if not_improving == tolerance:\n",
    "                        print(\"Stopping early due to tolerance threshold.\")\n",
    "                        break\n",
    "                else:\n",
    "                    not_improving = 0\n",
    "\n",
    "            last_loss = train_loss\n",
    "\n",
    "        torch.save(model.state_dict(), f\"{name_file}_model.pt\")\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        torch.save(model.state_dict(), f\"{name_file}_best_model.pt\")\n",
    "\n",
    "        torch.save(optimizer.state_dict(), f\"{name_file}_optimizer.pt\")\n",
    "        optimizer.load_state_dict(best_optimizer)\n",
    "        torch.save(optimizer.state_dict(), f\"{name_file}_best_optimizer.pt\")\n",
    "\n",
    "        if writing:\n",
    "            writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # encoding 768 image embedding to latent vector of size 256\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(768, 700),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(700, 640),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(640, 526),\n",
    "        )\n",
    "        # decoding latent vector of size 526 to 768 image embedding\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(526, 640),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(640, 700),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(700, 768),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: input embedding\n",
    "        :return: reconstructed image\n",
    "        \"\"\"\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "\n",
    "class AutoEncoderGELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # encoding 768 image embedding to latent vector of size 526\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(768, 700),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(700, 640),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(640, 526),\n",
    "        )\n",
    "        # decoding latent vector of size 526 to 768 image embedding\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(526, 640),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(640, 700),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(700, 768),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: input embedding\n",
    "        :return: reconstructed image\n",
    "        \"\"\"\n",
    "        return self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_path, scalar: float = 1.0):\n",
    "        self.embeddings = np.load(file_path)\n",
    "        # for i in range(len(self.embeddings)):\n",
    "        #     self.embeddings[i] = torch.tensor(self.embeddings[i], dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.embeddings[idx], dtype=torch.float32)\n",
    "\n",
    "\n",
    "dataset = EmbeddingsDataset(\"../data/embeddings_all/all.npy\")\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, test_size]\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "# model = AutoEncoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './dataset/train/data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m col_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings_small_pca\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m low_dataset \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/pca.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m cropper \u001b[38;5;241m=\u001b[39m \u001b[43mDetectionCut\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m client \u001b[38;5;241m=\u001b[39m qdrant_client(host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m\"\u001b[39m, port\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6333\u001b[39m)\n\u001b[1;32m     14\u001b[0m client\u001b[38;5;241m.\u001b[39mcreate_collection(\n\u001b[1;32m     15\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcol_name,\n\u001b[1;32m     16\u001b[0m     vectors_config\u001b[38;5;241m=\u001b[39mVectorParams(size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m526\u001b[39m, distance\u001b[38;5;241m=\u001b[39mDistance\u001b[38;5;241m.\u001b[39mCOSINE),\n\u001b[1;32m     17\u001b[0m )\n",
      "Cell \u001b[0;32mIn[65], line 51\u001b[0m, in \u001b[0;36mDetectionCut.__init__\u001b[0;34m(self, path, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./dataset/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m     50\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8l-oiv7.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m     labels_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[65], line 22\u001b[0m, in \u001b[0;36mImageProcessingBase.__init__\u001b[0;34m(self, path, *args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m=\u001b[39m path\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m image_files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_names \u001b[38;5;241m=\u001b[39m [file \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m image_files]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_ids \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(file)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m image_files]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset/train/data'"
     ]
    }
   ],
   "source": [
    "import qdrant_client\n",
    "\n",
    "from qdrant_client.models import Distance, HnswConfig, PointStruct, VectorParams\n",
    "from qdrant_client import models\n",
    "\n",
    "\n",
    "col_name = \"embeddings_small_pca\"\n",
    "\n",
    "low_dataset = np.load(f\"../data/{col_name}/pca.npy\")\n",
    "\n",
    "cropper = DetectionCut()\n",
    "client = qdrant_client(host=\"localhost\", port=6333)\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=col_name,\n",
    "    vectors_config=VectorParams(size=526, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "if not client.collection_exists(collection_name=col_name):\n",
    "    client.update_collection(\n",
    "        collection_name=col_name,\n",
    "        hnsw_config=models.HnswConfigDiff(\n",
    "            m=64,  # Number of bi-directional links created for every new element during construction\n",
    "            ef_construct=526,  # Size of the dynamic list for the nearest neighbors (used during the index construction)\n",
    "            full_scan_threshold=10000,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "images_count = len(cropper)\n",
    "counter = 0\n",
    "\n",
    "for image_number in tqdm(range(images_count)):\n",
    "    image_name = cropper[image_number][\"image_name\"]\n",
    "\n",
    "    embeddings = np.load(\n",
    "        f\"./data/embeddings/emb{image_number}.npy\"\n",
    "    ).tolist()  # find the #n of embeddings per image\n",
    "\n",
    "    idx = range(counter, counter + len(embeddings))\n",
    "    counter += len(embeddings)\n",
    "\n",
    "    client.add(\n",
    "        vectors=low_dataset[counter : counter + len(embeddings)],\n",
    "        idx=[i for i in idx],\n",
    "        payload=[{\"source\": image_name} for _ in range(len(embeddings))],\n",
    "        collection_name=col_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data = np.load(\"../data/embeddings_all/all.npy\")\n",
    "\n",
    "pca = PCA(n_components=526).fit_transform(data)\n",
    "\n",
    "np.save(\n",
    "    f\"../data/embeddings_small_pca/pca\",\n",
    "    pca,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "\n",
    "gaussian = GaussianRandomProjection(n_components=526).fit_transform(data)\n",
    "np.save(\n",
    "    f\"../data/embeddings_small_gaussian/pca\",\n",
    "    gaussian,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoderGELU().to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"models/GELU_v2.1_best_model.pt\"))\n",
    "\n",
    "encoder = model.encoder\n",
    "\n",
    "all = []\n",
    "for i, item in enumerate(dataset):\n",
    "    all.append(encoder(item.to(device)).numpy(force=True))\n",
    "\n",
    "np.save(f\"../data/embeddings_small_AE/ae\", np.array(all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = -1\n",
    "epochs = 2000\n",
    "tolerance = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), lr=0.00001, amsgrad=True, weight_decay=0.001\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)\n",
    "w_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, last_epoch=warmup_steps, T_max=warmup_steps\n",
    ")\n",
    "\n",
    "train_metrics = [torchmetrics.MeanSquaredError()]\n",
    "test_metrics = [torchmetrics.MeanSquaredError()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.035956018 -0.05751817\n",
      "-0.060841937 -0.07590552\n",
      "0.060207605 -0.07399991\n",
      "-0.056212313 0.07860634\n",
      "-0.02123738 -0.110461384\n",
      "-0.030863283 0.11171735\n",
      "0.019928308 -0.12332687\n",
      "-0.041508403 0.0627038\n",
      "-0.067136034 -0.005350301\n",
      "-0.036321025 0.07327922\n",
      "-0.01676544 0.052037634\n",
      "0.0043183574 0.085151315\n",
      "-0.038686786 0.07464099\n",
      "-0.045696802 0.10243833\n",
      "-0.028292188 0.046476804\n",
      "-0.03212128 0.0847549\n",
      "-0.008800708 0.06936505\n",
      "-0.030022932 -0.08948092\n",
      "0.018128661 -0.06887015\n",
      "-0.062055808 -0.07055934\n",
      "-0.034882054 0.03864901\n",
      "0.002936802 -0.10332389\n",
      "-0.050292265 0.019230265\n",
      "-0.036061402 -0.08482669\n",
      "-0.006902722 0.045568906\n",
      "-0.030446703 -0.06664474\n",
      "-0.0066830837 0.07255484\n",
      "-0.025358798 0.02515921\n",
      "-0.06722091 -0.116143815\n",
      "-0.051527075 0.06499199\n",
      "-0.04721216 0.024811216\n",
      "0.0036045788 -0.06815653\n",
      "-0.038350064 -0.038732693\n",
      "-0.01885326 -0.10298958\n",
      "-0.033185136 0.022075552\n",
      "-0.0023803636 -0.13427618\n",
      "-0.051043082 -0.06584416\n",
      "-0.0089463275 0.02182226\n",
      "-0.046983935 0.06812547\n",
      "-0.023042731 -0.054241642\n",
      "-0.009452799 -0.11383503\n",
      "-0.048455026 -0.06696751\n",
      "-0.039420303 0.15497656\n",
      "0.038670387 0.070632115\n",
      "-0.031081483 0.036610067\n",
      "0.0118382 0.043359336\n",
      "-0.026097503 0.03211623\n",
      "-0.029243818 -0.06994661\n",
      "-0.04282217 -0.07921101\n",
      "-0.029679677 -0.12398087\n",
      "-0.014384684 -0.034642223\n",
      "-0.032830827 -0.017105019\n",
      "-0.002738857 0.045907103\n",
      "-0.030278865 -0.08772633\n",
      "-0.0521166 0.11549358\n",
      "-0.014966641 0.013367707\n",
      "-0.08059211 0.12193196\n",
      "-0.027285444 -0.12326887\n",
      "0.0036723863 0.0739537\n",
      "-0.011931447 -0.009607775\n",
      "-0.031693663 -0.079780616\n",
      "-0.03271244 -0.07405153\n",
      "-0.055566333 0.040527254\n",
      "-0.027922923 -0.06837661\n",
      "-0.05616438 -0.07503347\n",
      "0.0033083365 -0.096934035\n",
      "-0.065947644 0.0028351136\n",
      "-0.028709343 0.12260219\n",
      "-0.011021167 0.050337315\n",
      "-0.048124902 0.006698575\n",
      "-0.029733915 -0.027578078\n",
      "0.004113366 0.11611988\n",
      "-0.018012378 -0.096228085\n",
      "-0.030599803 -0.12279951\n",
      "0.0052091233 -0.11263406\n",
      "-0.046987798 0.07705833\n",
      "-0.02819423 0.01263825\n",
      "-0.004371414 0.045872733\n",
      "-0.048190795 0.013653964\n",
      "-0.011826546 -0.0069633527\n",
      "-0.048814513 -0.06442675\n",
      "0.013808362 -0.101698816\n",
      "-0.036548436 0.032998722\n",
      "0.011241949 -0.0052804295\n",
      "-0.034310766 -0.009260651\n",
      "-0.0539969 0.038429745\n",
      "-0.001627539 0.07573151\n",
      "-0.01901331 0.051281765\n",
      "-0.0033860903 -0.100353874\n",
      "-0.004280478 -0.042959496\n",
      "-0.038716044 -0.03431103\n",
      "-0.03237779 -0.06538801\n",
      "-0.055818215 -0.05915503\n",
      "-0.025355754 0.037298277\n",
      "-0.018856585 -0.090162285\n",
      "-0.020396285 0.0007599853\n",
      "-0.09532126 -0.052240267\n",
      "-0.021666303 -0.10348751\n",
      "-0.024297211 -0.09400955\n",
      "-0.08065754 -0.054980565\n",
      "-0.009025842 0.12574616\n",
      "-0.035341743 -0.0490921\n",
      "-0.014496595 -0.055033565\n",
      "-0.015062863 -0.0613424\n",
      "-0.010432515 -0.009259079\n",
      "-0.016196502 -0.04307723\n",
      "-0.078268126 -0.10086534\n",
      "-0.05467399 0.13529539\n",
      "-0.03299038 -0.06962145\n",
      "-0.04405231 -0.09645647\n",
      "-0.053144224 -0.037362598\n",
      "-0.023453688 0.11849743\n",
      "-0.029942295 -0.110447556\n",
      "-0.03060562 0.08389951\n",
      "0.010681277 -0.11003027\n",
      "-0.046037477 0.034882516\n",
      "-0.0063144485 0.01777444\n",
      "-0.0622563 0.14154634\n",
      "-0.010709363 -0.086117536\n",
      "-0.049143236 0.054623857\n",
      "-0.048941225 -0.0030267034\n",
      "-0.021262826 0.056069642\n",
      "-0.04582322 0.025244903\n",
      "-0.044273093 0.10419839\n",
      "-0.039004426 -0.12583554\n",
      "-0.035452522 -0.086828776\n",
      "0.030362278 0.033205528\n",
      "-0.04197986 -0.06756059\n",
      "-0.057367023 -0.056097604\n",
      "-0.00017019031 0.0022760238\n",
      "-0.02967386 -0.0729231\n",
      "0.017647987 0.11315622\n",
      "-0.053842086 -0.070070155\n",
      "-0.050681077 0.011911786\n",
      "-0.030788355 -0.019051498\n",
      "-0.052417107 -0.081782386\n",
      "-0.06526342 0.098345175\n",
      "0.02769131 -0.11029979\n",
      "-0.010422769 -0.079371385\n",
      "-0.04627346 -0.027422087\n",
      "0.034885723 -0.13981958\n",
      "-0.041004892 -0.079431586\n",
      "-0.0037148213 -0.07599189\n",
      "-0.030390033 -0.07646501\n",
      "-0.013160035 0.068385266\n",
      "-0.005803393 -0.10233139\n",
      "-0.018376559 0.06316821\n",
      "0.0073631923 0.028440513\n",
      "-0.064817674 0.0958114\n",
      "-0.02722739 -0.09219156\n",
      "-0.012479042 0.12922318\n",
      "-0.015550015 0.09163006\n",
      "-0.034362305 0.10105139\n",
      "-0.007070998 0.07960893\n",
      "-0.018243076 -0.117724314\n",
      "-0.060648575 0.14753076\n",
      "-0.05747846 -0.05918483\n",
      "0.004661621 0.050484326\n",
      "-0.051869836 -0.043972947\n",
      "-0.040270846 0.046731796\n",
      "-0.00053587445 -0.03860203\n",
      "-0.053353228 -0.010015021\n",
      "-0.04013753 -0.09880991\n",
      "-0.010964126 -0.005806259\n",
      "-0.03840251 0.078211576\n",
      "-0.04015212 -0.012305915\n",
      "0.012789363 0.07750224\n",
      "-0.0155165 0.016574584\n",
      "-0.017940432 0.080385946\n",
      "-0.02719075 0.023162402\n",
      "-0.026694715 0.06872063\n",
      "-0.004151006 0.105632186\n",
      "-0.029359644 0.06321901\n",
      "-0.019765666 0.07874686\n",
      "-0.035615455 -0.12009005\n",
      "-0.030718544 -0.09575226\n",
      "-0.07660952 0.03400018\n",
      "-0.062745206 -0.060149275\n",
      "-0.00414638 -0.031779498\n",
      "-0.082413785 0.0037909523\n",
      "0.008783868 -0.05869105\n",
      "-0.024893202 -0.058596283\n",
      "-0.00040145064 0.013893574\n",
      "-0.016733848 -0.08081084\n",
      "-0.034840472 -0.012412541\n",
      "-0.0075036655 0.11252215\n",
      "-0.012049319 0.025181403\n",
      "-0.036324777 -0.07919272\n",
      "-0.019994097 0.07057286\n",
      "-0.0061525493 0.03264617\n",
      "-0.025993507 -0.12622482\n",
      "-0.041308716 -0.084871635\n",
      "-0.0756904 0.10256341\n",
      "-0.006171163 0.06532984\n",
      "-0.047479756 0.155642\n",
      "-0.0021470706 0.11905439\n",
      "-0.022916982 0.058066636\n",
      "-0.0076753865 -0.09975887\n",
      "-0.041922987 0.0038106088\n",
      "-0.053608082 0.09532578\n",
      "-0.039486416 0.09602879\n",
      "0.01993722 0.036455963\n",
      "0.010520319 -0.059783384\n",
      "-0.04716557 -0.08613093\n",
      "-0.020965729 0.06299888\n",
      "-0.025853237 0.13897169\n",
      "-0.08354843 -0.068357915\n",
      "-0.024490325 0.06062756\n",
      "-0.067692906 0.006944375\n",
      "-0.013241974 -0.045117542\n",
      "-0.0045995605 0.0017667823\n",
      "0.021163763 -0.014618712\n",
      "-0.035452466 -0.11622014\n",
      "-0.05436888 0.043951396\n",
      "-0.058597315 -0.033692162\n",
      "-0.040188376 -0.15937766\n",
      "-0.008655204 -0.017732255\n",
      "-0.0012667236 0.08761689\n",
      "-0.019315714 0.068049334\n",
      "0.028570166 -0.08735174\n",
      "-0.0073218704 -0.026997427\n",
      "-0.033003725 -0.09253079\n",
      "-0.0059008338 0.021586766\n",
      "-0.046427168 -0.10450245\n",
      "-0.061464503 0.060176723\n",
      "-0.025322888 -0.11950591\n",
      "-0.0104126 0.12631913\n",
      "-0.0013241314 -0.08296021\n",
      "-0.03483754 0.079232186\n",
      "-0.021574704 -0.06526048\n",
      "-0.0031739736 0.07747663\n",
      "-0.025939023 0.14614996\n",
      "-0.015835267 0.08809428\n",
      "5.403561e-05 0.11833226\n",
      "-0.04772499 0.032713197\n",
      "-0.004510094 0.10009456\n",
      "-0.016939435 0.060840975\n",
      "-0.008867099 -0.09025821\n",
      "-0.03396706 -0.08301725\n",
      "-0.01831163 -0.0035529379\n",
      "-0.023980012 -0.100757174\n",
      "-0.03313037 -0.06295189\n",
      "-0.047178958 -0.082639985\n",
      "0.011079591 0.061982635\n",
      "-0.01751624 0.03070608\n",
      "-0.017248603 -0.017048225\n",
      "-0.049419742 -0.086694665\n",
      "-0.025878057 -0.029547557\n",
      "-0.04752602 -0.056351278\n",
      "-0.021686912 -0.095894456\n",
      "-0.044553738 0.046176165\n",
      "-0.025944682 -0.11448043\n",
      "0.0072387564 -0.045492847\n",
      "-0.02985336 0.10773447\n",
      "0.0013390497 -0.040567912\n",
      "-0.0678481 0.07993905\n",
      "-0.08092951 0.113203436\n",
      "-0.02293121 -0.0269932\n",
      "-0.088549085 -0.08068983\n",
      "-0.028091868 -0.11455344\n",
      "-0.06892253 0.05247726\n",
      "0.009636233 0.11242896\n",
      "-0.012434266 0.09990458\n",
      "0.0032270856 0.08909388\n",
      "-0.033398293 -0.04366435\n",
      "-0.018393693 -0.094961\n",
      "-0.05499113 -0.08368486\n",
      "-0.01639015 -0.13033915\n",
      "-0.012383351 -0.02741921\n",
      "-0.033311587 0.06964955\n",
      "-0.017499767 0.0641115\n",
      "-0.012724795 0.06649003\n",
      "0.018814443 -0.040091667\n",
      "-0.000590286 0.08204273\n",
      "-0.051755354 0.08619045\n",
      "-0.021776458 0.1395129\n",
      "-0.016215703 -0.13884598\n",
      "-0.031232316 -0.009370919\n",
      "-0.011974541 -0.091141865\n",
      "0.0017344003 -0.09872265\n",
      "-0.039303258 0.073157445\n",
      "-0.08450567 -0.069324076\n",
      "-0.012916731 0.050741956\n",
      "0.006962332 -0.055774953\n",
      "-0.051021356 -0.10249586\n",
      "-0.006391764 0.046695966\n",
      "-0.03937499 0.08974521\n",
      "-0.042506427 0.02968698\n",
      "-0.026128631 0.06650057\n",
      "-0.0605977 -0.09529018\n",
      "-0.039488073 -0.09017239\n",
      "-0.054077383 0.05139439\n",
      "-0.013771657 0.06984335\n",
      "-0.053223398 0.071098275\n",
      "-0.037361927 0.0064222626\n",
      "-0.023722043 -0.05465909\n",
      "0.005127774 0.011161059\n",
      "-0.017464207 -0.11233272\n",
      "-0.057092335 0.11075565\n",
      "-0.0016214568 -0.036358036\n",
      "-0.03634235 0.11526969\n",
      "-0.043765515 0.06430415\n",
      "-0.019659476 0.067121044\n",
      "0.0038050313 -0.054898415\n",
      "0.021497453 -0.073416695\n",
      "-0.057962876 0.0020072684\n",
      "-0.05919328 0.050317157\n",
      "-0.02875348 0.089164\n",
      "0.020116713 0.010859497\n",
      "-0.021438532 -0.112863235\n",
      "-0.057840884 -0.09255111\n",
      "-0.0053230133 0.10894857\n",
      "-0.004560821 0.06480297\n",
      "0.0041093417 -0.085906774\n",
      "-0.036971927 -0.067380875\n",
      "-0.06793851 0.07263352\n",
      "-0.022183942 -0.001843065\n",
      "-0.030724835 -0.1284698\n",
      "-0.033506196 -0.03094592\n",
      "-0.042716328 0.011891935\n",
      "-0.01969024 -0.06282042\n",
      "-0.06269439 -0.08378773\n",
      "-0.043606814 0.024265304\n",
      "-0.018888287 -0.059303675\n",
      "-0.018742166 0.101081245\n",
      "-0.05344798 0.059638996\n",
      "0.017336087 -0.059320368\n",
      "-0.0103527 -0.075795\n",
      "-0.009532635 0.0069572777\n",
      "0.0076258346 0.1074989\n",
      "-0.05139369 0.008708188\n",
      "-0.05271445 0.051622137\n",
      "-0.020618709 -0.056498006\n",
      "-0.06963809 -0.03210199\n",
      "-0.011038741 -0.07665\n",
      "-0.033332184 0.008812565\n",
      "-0.031064056 0.10503349\n",
      "-0.031426318 0.10392325\n",
      "-0.02108316 0.07671111\n",
      "-0.023295004 0.019296214\n",
      "-0.015865812 -0.06993984\n",
      "-0.044781987 0.023023695\n",
      "-0.030682823 -0.036483772\n",
      "-0.05165682 0.08828986\n",
      "-0.038769644 0.0018970538\n",
      "-0.008837249 0.012082709\n",
      "-0.018312257 0.004959491\n",
      "-0.019074494 -0.033116627\n",
      "-0.046203185 -0.07834163\n",
      "-0.020946985 0.046272535\n",
      "-0.03965539 -0.1070406\n",
      "-0.013920095 -0.091206096\n",
      "-0.006231857 0.120160855\n",
      "-0.024191845 -0.0033681206\n",
      "-0.046658322 0.08240065\n",
      "-0.02532653 -0.06441643\n",
      "-0.055876035 0.08059638\n",
      "-0.033053663 -0.12812433\n",
      "-0.033791676 -0.086177744\n",
      "-0.04151085 0.065838344\n",
      "-0.006788695 0.04846445\n",
      "-0.029042967 -0.12589718\n",
      "-0.00749616 -0.13011898\n",
      "-0.018014945 -0.034545183\n",
      "-0.040199324 -0.12630494\n",
      "-0.05818305 -0.11678625\n",
      "-0.01684586 0.062450215\n",
      "-0.040307563 0.074218\n",
      "-0.033669524 -0.12808861\n",
      "-0.0010209912 0.022750236\n",
      "-0.041751575 -0.09892789\n",
      "-0.056075767 -0.069540545\n",
      "-0.030584248 -0.0827942\n",
      "0.020034665 0.06735644\n",
      "-0.04987894 0.043110654\n",
      "0.008188747 -0.05611603\n",
      "-0.0617878 -0.0118252365\n",
      "-0.010680653 0.10429312\n",
      "-0.03138889 -0.021140872\n",
      "-0.004828891 0.018495847\n",
      "-0.035478033 -0.05646813\n",
      "-0.030203752 0.08473651\n",
      "-0.023698539 0.10967243\n",
      "0.012578333 0.06391424\n",
      "-0.03958311 -0.060918454\n",
      "-0.008416268 -0.039491385\n",
      "-0.03318648 -0.0388951\n",
      "-0.051465683 -0.10569908\n",
      "-0.055531412 -0.08087084\n",
      "-0.027337253 -0.06747148\n",
      "-0.028265778 0.09337355\n",
      "0.0061720414 0.0010052025\n",
      "-0.023093402 -0.07365008\n",
      "-0.0667938 -0.12055081\n",
      "-0.030564671 -0.060867425\n",
      "-0.025108175 0.054041665\n",
      "-0.04117183 -0.08341979\n",
      "0.012063826 -0.07014872\n",
      "-0.04124106 -0.0819152\n",
      "0.0032902062 -0.09415887\n",
      "-0.032814916 0.03439116\n",
      "-0.05075892 -0.061763868\n",
      "-0.006168815 0.10062847\n",
      "-0.0076391315 -0.08139623\n",
      "-0.060273003 0.11376849\n",
      "-0.03915184 0.0067070755\n",
      "-0.01872963 -0.10120686\n",
      "-0.0151645765 -0.09765458\n",
      "-0.034222532 -0.027632184\n",
      "-0.032773767 -0.07526322\n",
      "-0.010358738 0.057269584\n",
      "-0.020848555 -0.0917878\n",
      "-0.042716373 0.05568596\n",
      "-0.042665504 0.050109293\n",
      "-0.07252143 -0.0714439\n",
      "-0.0011179363 0.051909596\n",
      "-0.018955605 -0.12769611\n",
      "-0.033338007 0.103453055\n",
      "-0.00611557 0.04957524\n",
      "0.001012207 -0.047768757\n",
      "-0.003839388 0.10872321\n",
      "7.209381e-05 0.06470347\n",
      "-0.0066634384 0.06897417\n",
      "-0.051624786 -0.083061725\n",
      "-0.051631045 0.0129785165\n",
      "0.003826235 -0.11636566\n",
      "-0.039116234 -0.00053114444\n",
      "-0.031104136 -0.044063233\n",
      "-0.04870854 -0.05302489\n",
      "-0.07183688 0.0013623536\n",
      "-0.01982912 0.049765747\n",
      "0.010626426 -0.008424971\n",
      "-0.0696727 -0.060022876\n",
      "-0.0057634185 0.029650219\n",
      "-0.022822594 0.053601343\n",
      "-0.08238521 -0.0810361\n",
      "-0.04635926 0.04054807\n",
      "-0.040928114 -0.047643725\n",
      "-0.08651809 -0.054710127\n",
      "-0.054949887 -0.062096786\n",
      "-0.058944624 -0.015080542\n",
      "-0.02894029 -0.073489666\n",
      "-0.081563756 -0.093844794\n",
      "-0.016585492 -0.037806638\n",
      "0.0147579545 0.11634278\n",
      "-0.03858028 0.0456393\n",
      "-0.027131965 -0.09607315\n",
      "0.025277786 -0.09601013\n",
      "-0.005411154 0.08290617\n",
      "-0.017140796 -0.052480422\n",
      "-0.010025065 -0.1069573\n",
      "-0.05023245 0.031750165\n",
      "-0.0578091 0.12396402\n",
      "-0.0005835717 -0.043818228\n",
      "0.0057657547 -0.13539132\n",
      "-0.010018571 -0.09686309\n",
      "-0.054935403 -0.038215257\n",
      "-0.002043703 -0.0668037\n",
      "-0.043756846 0.11076814\n",
      "-0.04576188 0.013141801\n",
      "-0.012777055 -0.06404378\n",
      "-0.05432364 0.09825175\n",
      "-0.038643017 0.0070942175\n",
      "-0.06882018 -0.09712802\n",
      "0.01667874 -0.099098936\n",
      "-0.025307447 -0.071192645\n",
      "-0.04538271 0.09548744\n",
      "-0.05072447 -0.06633825\n",
      "-0.049914856 0.10579908\n",
      "-0.02234999 -0.099400505\n",
      "-0.045054853 -0.017339187\n",
      "0.009592569 0.020978115\n",
      "-0.009303466 -0.041761402\n",
      "-0.017130679 0.088460535\n",
      "0.014844603 -0.016277563\n",
      "-0.025546728 -0.0093070725\n",
      "-0.026495082 -0.10254072\n",
      "-0.06950864 -0.097972564\n",
      "-0.044758722 0.012293608\n",
      "-0.015945012 -0.124633014\n",
      "-0.031547517 0.11200525\n",
      "-0.044743642 -0.014771666\n",
      "-0.085269235 0.11275968\n",
      "-0.061328825 -0.10393773\n",
      "-9.480214e-05 -0.027867276\n",
      "0.011408304 -0.115020566\n",
      "-0.00780871 0.08251061\n",
      "-0.030794857 -0.09849246\n",
      "-0.0018832334 0.11385279\n",
      "-0.022741191 0.10079625\n",
      "0.012645142 -0.09424054\n",
      "-0.015293159 0.14789419\n",
      "-0.0077407653 -0.101790175\n",
      "-0.031077044 -0.051133014\n",
      "-0.06159454 -0.120890856\n",
      "-0.05751947 0.119109586\n",
      "-0.010204225 0.10840095\n",
      "0.0005740662 0.034406602\n",
      "-0.030495744 -0.041127827\n",
      "-0.05052118 -0.056943007\n",
      "-0.04910638 0.064515255\n",
      "-0.009672608 0.089334935\n",
      "-0.024372004 -0.023199534\n",
      "-0.010675157 -0.11101055\n",
      "-0.05457322 -0.08537954\n",
      "-0.012860271 0.03991132\n",
      "0.0026747093 -0.04688352\n",
      "-0.073950134 -0.13354096\n",
      "-0.028460145 0.1432928\n",
      "-0.029584417 0.06813949\n",
      "-0.0037274098 0.0887842\n",
      "0.010406258 -0.0025225198\n",
      "-0.032023005 -0.123510964\n",
      "-0.028540751 0.0026860945\n",
      "-0.015696628 0.1046176\n",
      "-0.03793446 -0.10061596\n",
      "-0.049068972 0.019866087\n",
      "0.024007319 0.08281325\n",
      "-0.0054797186 0.084951855\n",
      "-0.037329774 0.08367363\n",
      "0.012330488 -0.12426406\n",
      "-5.165052e-05 -0.109236516\n",
      "0.006046974 -0.09390153\n",
      "0.018235005 0.06157107\n",
      "-0.039484795 0.036765993\n",
      "-0.012232466 -0.04294051\n"
     ]
    }
   ],
   "source": [
    "vector = dataset[0].to(device)\n",
    "\n",
    "model.eval()\n",
    "m_vector = encoder(vector)\n",
    "for i, j in zip(vector, m_vector):\n",
    "    print(i.float().numpy(force=True), j.float().numpy(force=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver()\n",
    "solver.training(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=epochs,\n",
    "    name_file=\"GELU_v2.1\",\n",
    "    metrics=train_metrics,\n",
    "    writing=True,\n",
    "    warmup_steps=warmup_steps,\n",
    "    warmup_scheduler=w_scheduler,\n",
    "    tolerance=tolerance,\n",
    "    tolerance_delta=1e-7,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLS_team",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
